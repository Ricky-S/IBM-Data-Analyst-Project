|Term	|Definition|
|---|---|
|Data augmentation	|A technique commonly used in machine learning and deep learning to increase the diversity and amount of training data.|
|Deep learning	|A subset of machine learning that focuses on training computers to perform tasks by learning from data. It uses artificial neural networks.|
|Diffusion model	|A type of generative model that is popularly used for generating high-quality samples and performing various tasks, including image synthesis. They are trained by gradually adding noise to an image and then learning to remove the noise. This process is called diffusion.|
|Discriminative AI	|A type of artificial intelligence that distinguishes between different classes of data.|
|Discriminative AI models	|Models that identify and classify based on patterns they observe in training data. In general, they are used in prediction and classification tasks.|
|Foundation models	|AI models with broad capabilities that can be adapted to create more specialized models or tools for specific use cases.|
|Generative adversarial network (GAN)	|A type of generative model that includes two neural networks: generator and discriminator. The generator is trained on vast data sets to create samples like text and images. The discriminator tries to distinguish whether the sample is real or fake.|
|Generative AI	|A type of artificial intelligence that can create new content, such as text, images, audio, and video.|
|Generative AI models	|Models that can understand the context of input content to generate new content. In general, they are used for automated content creation and interactive communication.|
|Generative pre-trained transformer (GPT)	|A series of large language models developed by OpenAI. They are designed to understand language by leveraging a combination of two concepts: training and transformers.|
|Large language models (LLMs)	|A type of deep learning model trained on massive amounts of text data to learn the patterns and structures of language. They can perform language-related tasks, including text generation, translation, summarization, sentiment analysis, and more.|
|Machine learning	|A type of artificial intelligence that focuses on creating algorithms and models that enable computers to learn and make predictions or decisions. It involves designing systems that can learn from training data.|
|Natural language processing (NLP)	|A branch of artificial intelligence that enables computers to understand, manipulate and generate human language (natural language).|
|Neural networks	|Computational models inspired by the structure and functioning of the human brain. They are a fundamental component of deep learning and artificial intelligence.|
|Prompt	|Instructions or questions that are given to a generative AI model to generate new content.|
|Training data	|Data (generally, large datasets that also have examples) used to teach a machine learning model.|
|Transformers	|A deep learning architecture that uses an encoder-decoder mechanism. Transformers can generate coherent and contextually relevant text.|
|Variational autoencoder (VAE)	|A type of generative model that is basically a neural network model designed to learn the efficient representation of input data by encoding it into a smaller space and decoding back to the original space.|


|Term	|Definition|
|---|---|
|Term	|Definition|
API integration	|Application programming interface integration refers to the process of connecting different software systems or applications through their APIs to enable them to work together and share data or functionality.|
Bias mitigation	|A technique in which text prompts provide explicit instructions to generate neutral responses.|
Chain-of-Thought	|An approach to prompt engineering that involves breaking down a complex task into smaller and easier ones through a sequence of more straightforward prompts.|
ChatGPT	|A language model designed to provide detailed responses to natural language input.|
Claude	|A powerful and flexible AI chatbot to help you with your tasks.|
Contextual guidance	|A technique using which text prompts provide specific instructions to the LLMs to generate relevant output.|
DALL-E	|Text-to-image model that generates digital images from natural language descriptions.|
Domain expertise	|A technique wherein text prompts can use domain-specific terminology to generate content in specialized fields like medicine, law, or engineering, where accuracy and precision are crucial.|
Dust	|A prompt engineering tool that provides a web user interface for writing prompts and chaining them together.
Explainability	|Refers to the degree to which a user can understand and interpret the model's decision-making process and the reasons behind its generated outputs.|
Few-shot prompting	|A method that enables context learning, wherein demonstrations are provided in the prompt to steer the model to better performance.|
Framing	|A technique by which text prompts guide LLMs to generate responses within the required boundaries.|
Generative AI	|A type of artificial intelligence that can create new content, such as text, images, audio, and video.
Generative AI models	|Models that can understand the context of input content to generate new content. In general, they are used for automated content creation and interactive communication.|
GPT	|Generative pre-trained transformers or GPT are a family of neural networks that uses transformer architecture to create human-like text or content as output.|
IBM watsonx.ai	|A platform of integrated tools to train, tune, deploy, and manage foundation models easily.|
Integrated Development Environment (IDE)	|A software tool for crafting and executing prompts that engage with language models.|
Input data	|Any piece of information provided as part of the prompt.|
Interview pattern approach	|A prompt engineering strategy that involves designing prompts by simulating a conversation or interacting with the model in the style of an interview.|
LangChain	|A Python library that provides functionalities for building and chaining prompts.|
Large language models (LLMs)	|A type of deep learning model trained on massive amounts of text data to learn the patterns and structures of language. They can perform language-related tasks, including text generation, translation, summarization, sentiment analysis, and more.|
Midjourney	|A text-to-image model that generates images from natural language requests.|
Naive prompting	|Asking queries from the model in the simplest possible manner.|
Natural language processing (NLP)	|A branch of artificial intelligence that enables computers to understand, manipulate, and generate human language (natural language).|
OpenAI Playground	|A web-based tool that helps to experiment and test prompts with various models of OpenAI, such as GPT.|
Output indicator	|Benchmarks for assessing the attributes of the output generated by the model.|
Prompt	|Instructions or questions given to a generative AI model to generate new content.|
Prompt engineering	|The process of designing effective prompts to generate better and desired responses.|
PromptBase	|A marketplace for selling and buying prompts.|
Prompt lab	|A tool that enables users to experiment with prompts based on different foundation models and build prompts based on their needs.|
PromptPerfect	|A tool used to optimize prompts for different LLMs or text-to-image models.|
Role-play/Persona pattern	|Specific format or structure for constructing prompts that involve the perspective of a character or persona.|
Scale AI	|A technology company that specializes in data labeling and data annotation services.|
Stable Diffusion	|A text-to-image model that generates detailed images based on text descriptions.|
StableLM	|An open-source language model based on a dataset that contains trillions of tokens of content.|
Tree-of-Thought	|An approach to prompt engineering that involves hierarchically structuring a prompt or query, akin to a tree structure, to specify the desired line of thinking or reasoning for the model.|
User feedback loop	|A technique wherein users provide feedback to text prompts and iteratively refine them based on the response generated by the LLM.|
Zero-shot prompting	|A method using which generative AI models generate meaningful responses to prompts without needing prior training on those specific prompts.|