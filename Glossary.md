|Term	|Definition|
|---|---|
|Data augmentation	|A technique commonly used in machine learning and deep learning to increase the diversity and amount of training data.|
|Deep learning	|A subset of machine learning that focuses on training computers to perform tasks by learning from data. It uses artificial neural networks.|
|Diffusion model	|A type of generative model that is popularly used for generating high-quality samples and performing various tasks, including image synthesis. They are trained by gradually adding noise to an image and then learning to remove the noise. This process is called diffusion.|
|Discriminative AI	|A type of artificial intelligence that distinguishes between different classes of data.|
|Discriminative AI models	|Models that identify and classify based on patterns they observe in training data. In general, they are used in prediction and classification tasks.|
|Foundation models	|AI models with broad capabilities that can be adapted to create more specialized models or tools for specific use cases.|
|Generative adversarial network (GAN)	|A type of generative model that includes two neural networks: generator and discriminator. The generator is trained on vast data sets to create samples like text and images. The discriminator tries to distinguish whether the sample is real or fake.|
|Generative AI	|A type of artificial intelligence that can create new content, such as text, images, audio, and video.|
|Generative AI models	|Models that can understand the context of input content to generate new content. In general, they are used for automated content creation and interactive communication.|
|Generative pre-trained transformer (GPT)	|A series of large language models developed by OpenAI. They are designed to understand language by leveraging a combination of two concepts: training and transformers.|
|Large language models (LLMs)	|A type of deep learning model trained on massive amounts of text data to learn the patterns and structures of language. They can perform language-related tasks, including text generation, translation, summarization, sentiment analysis, and more.|
|Machine learning	|A type of artificial intelligence that focuses on creating algorithms and models that enable computers to learn and make predictions or decisions. It involves designing systems that can learn from training data.|
|Natural language processing (NLP)	|A branch of artificial intelligence that enables computers to understand, manipulate and generate human language (natural language).|
|Neural networks	|Computational models inspired by the structure and functioning of the human brain. They are a fundamental component of deep learning and artificial intelligence.|
|Prompt	|Instructions or questions that are given to a generative AI model to generate new content.|
|Training data	|Data (generally, large datasets that also have examples) used to teach a machine learning model.|
|Transformers	|A deep learning architecture that uses an encoder-decoder mechanism. Transformers can generate coherent and contextually relevant text.|
|Variational autoencoder (VAE)	|A type of generative model that is basically a neural network model designed to learn the efficient representation of input data by encoding it into a smaller space and decoding back to the original space.|