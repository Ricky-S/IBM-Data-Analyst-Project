{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ba6adf-899a-4d1b-8fef-8dbff7961c3d",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0bbc2-ae7f-4a0b-8980-17c4041d2da2",
   "metadata": {},
   "source": [
    "# **Finding Duplicates Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869441e-4dd8-4342-a60e-65c76178e68f",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8619868-fba6-49c3-b9b7-231f75d12e57",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6f1a1-d65c-4a18-9e16-374d8f7c42bb",
   "metadata": {},
   "source": [
    "Data wrangling is a critical step in preparing datasets for analysis, and handling duplicates plays a key role in ensuring data accuracy. In this lab, you will focus on identifying and removing duplicate entries from your dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ecff9-dab1-4cc2-beb3-4f1a5d30e63a",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc43558-2337-4194-b8c8-4a5c039eeaf6",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6312dd-babe-40a5-aaae-36a62b6e8611",
   "metadata": {},
   "source": [
    "1. Identify duplicate rows in the dataset and analyze their characteristics.\n",
    "2. Visualize the distribution of duplicates based on key attributes.\n",
    "3. Remove duplicate values strategically based on specific criteria.\n",
    "4. Outline the process of verifying and documenting duplicate removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef296f-408a-47a3-be2c-a8f88b8aa28b",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f514a-de04-4b17-895e-4816feae9014",
   "metadata": {},
   "source": [
    "Install the needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b854470-d006-4920-b31a-f6e48680868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e465a-fef2-4c67-936f-7464a256fa27",
   "metadata": {},
   "source": [
    "Import pandas module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23350c56-404a-4e5a-98df-13efc3d42721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a6ee3-c916-4135-959a-d8dbcdf7eea4",
   "metadata": {},
   "source": [
    "Import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6086862-b313-40a8-9b87-977001780829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc845c0-7245-4496-8254-a873230e0c71",
   "metadata": {},
   "source": [
    "## **Load the dataset into a dataframe**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ad537-b5ee-49f6-a44a-39ed379dd432",
   "metadata": {},
   "source": [
    "<h2>Read Data</h2>\n",
    "<p>\n",
    "We utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad28251-3856-4aed-bbbf-9efbd0c81126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset directly from the URL\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# df['Country'].value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3ff85-e593-4184-b832-657ec78658d4",
   "metadata": {},
   "source": [
    "Load the data into a pandas dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61855c-0e6f-4654-9aaf-f88162895e1b",
   "metadata": {},
   "source": [
    "Note: If you are working on a local Jupyter environment, you can use the URL directly in the pandas.read_csv() function as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce791b69-efd6-473b-ad12-642e882058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbff81-73de-4ec5-9ffe-8d7a966ef78e",
   "metadata": {},
   "source": [
    "## Identify and Analyze Duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7d74c-ac1c-42aa-b675-aecbd316261e",
   "metadata": {},
   "source": [
    "### Task 1: Identify Duplicate Rows\n",
    "1. Count the number of duplicate rows in the dataset.\n",
    "3. Display the first few duplicate rows to understand their structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24827b-0c15-4170-920b-f30a69aed08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# identify duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047d72c-ecfc-41d4-aa7a-3bc5eb4b4f69",
   "metadata": {},
   "source": [
    "### Task 2: Analyze Characteristics of Duplicates\n",
    "1. Identify which columns have the same values in duplicate rows.\n",
    "2. Analyze the distribution of duplicates across different columns such as Country, Employment, and DevType.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd30095-0264-45dc-9788-bf516b60a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# analyse the distribution for duplicates for columns Country, Employment, DevType\n",
    "duplicates = df.duplicated(subset=['Country', 'Employment', 'DevType'])\n",
    "duplicates.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d43e80-7523-4a79-98f2-09faf0369f00",
   "metadata": {},
   "source": [
    "### Task 3: Visualize Duplicates Distribution\n",
    "1. Create visualizations to show the distribution of duplicates across different categories.\n",
    "2. Use bar charts or pie charts to represent the distribution of duplicates by Country and Employment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21f745-0ccf-415b-bd4e-d22702449c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# Task 3: Visualize Duplicates Distribution\n",
    "# 1. Create visualizations to show the distribution of duplicates across different categories.\n",
    "# 2. Use bar charts or pie charts to represent the distribution of duplicates by Country and Employment.\n",
    "\n",
    "# Distribution of duplicates by Country\n",
    "country_duplicates = df[duplicates].Country.value_counts()\n",
    "country_duplicates.plot(kind='bar', figsize=(12, 6), title='Duplicate Rows by Country')\n",
    "plt.show()\n",
    "\n",
    "# Question 3\n",
    "# calculate duplicate values are there in the “Country” column in the 2024 dataset?\n",
    "country_duplicates = df[duplicates].Country.value_counts()\n",
    "print(f\"country_duplicates: {len(country_duplicates)}\")\n",
    "len(df['Country'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c21aee-b43f-4e96-a5cf-4271a3b0edaa",
   "metadata": {},
   "source": [
    "### Task 4: Strategic Removal of Duplicates\n",
    "1. Decide which columns are critical for defining uniqueness in the dataset.\n",
    "2. Remove duplicates based on a subset of columns if complete row duplication is not a good criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c5a37-f108-4715-9753-28420b6b1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559965df-17bd-4293-8f8a-d4d2f05518a1",
   "metadata": {},
   "source": [
    "## Verify and Document Duplicate Removal Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182c4af-9195-427b-8be6-9ea116d18aaf",
   "metadata": {},
   "source": [
    "### Task 5: Documentation\n",
    "1. Document the process of identifying and removing duplicates.\n",
    "2. Provide insights into why certain columns were chosen for duplicate removal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a860-2743-444f-b9c0-0546111d1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718378a-fa8c-4da7-9db5-d45b66cf2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dd21d-f6b4-4557-9b7e-48f075107555",
   "metadata": {},
   "source": [
    "### Summary and Next Steps\n",
    "**In this lab, you focused on identifying and analyzing duplicate rows within the dataset.**\n",
    "\n",
    "- You employed various techniques to explore the nature of duplicates and applied strategic methods for their removal.\n",
    "- For additional analysis, consider investigating the impact of duplicates on specific analyses and how their removal affects the results.\n",
    "- This version of the lab is more focused on duplicate analysis and handling, providing a structured approach to deal with duplicates in a dataset effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722e93f-b7f3-44a7-910c-df7a6584aecf",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11- 05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-28|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a8891-a8be-41e5-bb23-8a740331a0cc",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "prev_pub_hash": "9d3843d777dd6ae698226e484863641e91bffec3236e859bbdfb62112f6fb9e3"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
